{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-modal Semantic Extraction\n",
    "\n",
    "Before building up a fine-grained pipeline to ingest, partition and stage the documents, we might first develop a simple demo by directly ingesting a page to GPT-4o as our baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if using DefaultAzureCredential below\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# This is the name of the model deployed, such as 'gpt-4' or 'gpt-3.5-turbo\n",
    "model = os.getenv(\"AZUREAI_CHAT_MODEL\", \"gpt-4o\")\n",
    "\n",
    "# This is the deployment URL, as provided in the Azure AI playground ('view code')\n",
    "# It will end with 'openai.azure.com'\n",
    "azure_endpoint = os.getenv(\"AZUREAI_CHAT_BASE_ENDPOINT\")\n",
    "\n",
    "# This is the name of the deployment specified in the Azure portal\n",
    "azure_deployment = os.getenv(\"AZUREAI_CHAT_DEPLOYMENT\")\n",
    "\n",
    "# This is the deployed API version, such as 2024-02-15-preview\n",
    "azure_api_version = os.getenv(\"AZUREAI_CHAT_API_VERSION\")\n",
    "\n",
    "# The environment variable should be set to the API key from the Azure AI playground:\n",
    "api_key=os.getenv(\"AZUREAI_CHAT_KEY\")\n",
    "\n",
    "# Alternatively, we can use Entra authentication\n",
    "token_provider = get_bearer_token_provider(\n",
    "     DefaultAzureCredential(),\n",
    "     \"https://cognitiveservices.azure.com/.default\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from guidance import system, user, assistant, gen, models\n",
    "\n",
    "azureai_model = models.AzureOpenAI(\n",
    "    model=model,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    azure_deployment=azure_deployment,\n",
    "    version=azure_api_version,\n",
    "    api_key=api_key,\n",
    "    max_streaming_tokens=4096\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "GoogleAuthError",
     "evalue": "Unable to find your project. Please provide a project ID by:\n- Passing a constructor argument\n- Using vertexai.init()\n- Setting project using 'gcloud config set project my-project'\n- Setting a GCP environment variable\n- To create a Google Cloud project, please follow guidance at https://developers.google.com/workspace/guides/create-project",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDefaultCredentialsError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\google\\cloud\\aiplatform\\initializer.py:356\u001b[0m, in \u001b[0;36m_Config.project\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 356\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_project_as_env_var_or_google_auth_default()\n\u001b[0;32m    357\u001b[0m     project_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_project\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\google\\cloud\\aiplatform\\initializer.py:112\u001b[0m, in \u001b[0;36m_Config._set_project_as_env_var_or_google_auth_default\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 112\u001b[0m     credentials, project \u001b[38;5;241m=\u001b[39m google\u001b[38;5;241m.\u001b[39mauth\u001b[38;5;241m.\u001b[39mdefault()\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_credentials \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_credentials \u001b[38;5;129;01mor\u001b[39;00m credentials\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\google\\auth\\_default.py:691\u001b[0m, in \u001b[0;36mdefault\u001b[1;34m(scopes, request, quota_project_id, default_scopes)\u001b[0m\n\u001b[0;32m    689\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m credentials, effective_project_id\n\u001b[1;32m--> 691\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mDefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\n",
      "\u001b[1;31mDefaultCredentialsError\u001b[0m: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mGoogleAuthError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mguidance\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m system, user, assistant, image, models\n\u001b[0;32m      3\u001b[0m gai_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGOOGLE_CHAT_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m gemini \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mVertexAI(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemini-pro-vision\u001b[39m\u001b[38;5;124m\"\u001b[39m, api_key\u001b[38;5;241m=\u001b[39mgai_key)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m user():\n\u001b[0;32m      7\u001b[0m     lm \u001b[38;5;241m=\u001b[39m gemini \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is this a picture of?\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m image(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./table-6-13.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\guidance\\models\\vertexai\\_vertexai.py:76\u001b[0m, in \u001b[0;36mVertexAI.__init__\u001b[1;34m(self, model, tokenizer, echo, max_streaming_tokens, timeout, compute_log_probs, engine_class, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m found_subclass \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;241m=\u001b[39m found_subclass\n\u001b[1;32m---> 76\u001b[0m     found_subclass\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     77\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     78\u001b[0m         model,\n\u001b[0;32m     79\u001b[0m         tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[0;32m     80\u001b[0m         echo\u001b[38;5;241m=\u001b[39mecho,\n\u001b[0;32m     81\u001b[0m         max_streaming_tokens\u001b[38;5;241m=\u001b[39mmax_streaming_tokens,\n\u001b[0;32m     82\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     83\u001b[0m     )\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m  \u001b[38;5;66;03m# we return since we just ran init above and don't need to run again\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# make sure we have a valid model object\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\guidance\\models\\vertexai\\_Gemini.py:95\u001b[0m, in \u001b[0;36mGeminiChat.__init__\u001b[1;34m(self, model, tokenizer, echo, max_streaming_tokens, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28mself\u001b[39m, model, tokenizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, echo\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_streaming_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m     93\u001b[0m ):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m---> 95\u001b[0m         model \u001b[38;5;241m=\u001b[39m GenerativeModel(model)\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;66;03m# Gemini does not have a public tokenizer, so we pretend it tokenizes like gpt2...\u001b[39;00m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\vertexai\\generative_models\\_generative_models.py:353\u001b[0m, in \u001b[0;36m_GenerativeModel.__init__\u001b[1;34m(self, model_name, generation_config, safety_settings, tools, tool_config, system_instruction, labels)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    324\u001b[0m     model_name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    331\u001b[0m     labels: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    332\u001b[0m ):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Initializes GenerativeModel.\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \n\u001b[0;32m    335\u001b[0m \u001b[38;5;124;03m    Usage:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;124;03m        labels: labels that will be passed to billing for cost tracking.\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 353\u001b[0m     project \u001b[38;5;241m=\u001b[39m aiplatform_initializer\u001b[38;5;241m.\u001b[39mglobal_config\u001b[38;5;241m.\u001b[39mproject\n\u001b[0;32m    354\u001b[0m     location \u001b[38;5;241m=\u001b[39m aiplatform_initializer\u001b[38;5;241m.\u001b[39mglobal_config\u001b[38;5;241m.\u001b[39mlocation\n\u001b[0;32m    355\u001b[0m     model_name \u001b[38;5;241m=\u001b[39m _reconcile_model_name(model_name, project, location)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\google\\cloud\\aiplatform\\initializer.py:359\u001b[0m, in \u001b[0;36m_Config.project\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    357\u001b[0m     project_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_project\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GoogleAuthError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m--> 359\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GoogleAuthError(project_not_found_exception_str) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m project_id \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key:\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(project_not_found_exception_str)\n",
      "\u001b[1;31mGoogleAuthError\u001b[0m: Unable to find your project. Please provide a project ID by:\n- Passing a constructor argument\n- Using vertexai.init()\n- Setting project using 'gcloud config set project my-project'\n- Setting a GCP environment variable\n- To create a Google Cloud project, please follow guidance at https://developers.google.com/workspace/guides/create-project"
     ]
    }
   ],
   "source": [
    "from guidance import system, user, assistant, image, models\n",
    "\n",
    "gai_key = os.getenv(\"GOOGLE_CHAT_KEY\")\n",
    "gemini = models.VertexAI(\"gemini-pro-vision\", api_key=gai_key)\n",
    "\n",
    "with user():\n",
    "    lm = gemini + \"What is this a picture of?\" + image(\"./table-6-13.jpg\")\n",
    "\n",
    "with assistant():\n",
    "    lm += gen(\"answer\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
